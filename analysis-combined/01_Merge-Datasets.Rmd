---
title: "Merge-Datasets"
output:
  html_document:
    df_print: paged
    toc: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE,
                      root.dir = "~/Projects/IBS_Meta-analysis_16S/")
```


##########
# IMPORT #
##########

## 1. Librairies

```{r import-library}
# Libraries
library(tidyverse)
library(phyloseq)
```

## 2. Data

```{r import-data}
# Data
path <- "~/Projects/IBS_Meta-analysis_16S"
physeq.fukui <- readRDS(file.path(path, "phyloseq-objects/physeq_fukui.rds"))
physeq.hugerth <- readRDS(file.path(path, "phyloseq-objects/physeq_hugerth.rds"))
physeq.labus <- readRDS(file.path(path, "phyloseq-objects/physeq_labus.rds"))
physeq.lopresti <- readRDS(file.path(path, "phyloseq-objects/physeq_lopresti.rds"))
physeq.nagel <- readRDS(file.path(path, "phyloseq-objects/physeq_nagel.rds"))
physeq.pozuelo <- readRDS(file.path(path, "phyloseq-objects/physeq_pozuelo.rds"))
physeq.zeber <- readRDS(file.path(path, "phyloseq-objects/physeq_zeber.rds"))
physeq.zhu <- readRDS(file.path(path, "phyloseq-objects/physeq_zhu.rds"))
physeq.zhuang <- readRDS(file.path(path, "phyloseq-objects/physeq_zhuang.rds"))

datasets <- list("Fukui" = physeq.fukui,
                 "Hugerth" = physeq.hugerth,
                 "Labus" = physeq.labus,
                 "LoPresti" = physeq.lopresti,
                 "Nagel" = physeq.nagel,
                 "Pozuelo" = physeq.pozuelo,
                 "Zeber-Lubecka" = physeq.zeber,
                 "Zhu" = physeq.zhu,
                 "Zhuang" = physeq.zhuang)
```


#####################
# MERGE COMMON ASVs #
#####################

## 1. Mock data
Let's try first on some mock data.

```{r mock-data}
#_______________________________________
# MOCK DATA
# Create mock data
df <- data.frame("author" = c("fukui", "fukui", "zhu", "pozuelo", "fukui"),
                 "ASV" = paste("ASV", rep(1:5), sep=""),
                 "Sequence" = c("ATTTGAC", "GCATTAGCTTTA", "TTTGA", "GCTATCG", "AGCTTTA"),
                 "Phylum" = c("Firmicutes", "Bacteroidota", "Firmicutes", "Actinobacteria", "Bacteroidota"),
                 "Class" = c("Clostridia", "Bacteria", "Clostridia", "Proteomachin", "Bacteria")) %>%
  arrange(nchar(Sequence))
head(df)

# Init
new.df <- data.frame(matrix(ncol=6, nrow=0))
colnames(new.df) <- c(colnames(df), "ASV_new")

allseq <- df$Sequence
i=1

# Identify ASVs with same sequence and give them same ASV reference
while(length(allseq) !=0 ){
  
  seq <- allseq[1]
  # cat("\n++ Sequence:", seq, "++\n")
  
  # Subset df by sequence
  tempdf <- df %>%
    filter(str_detect(Sequence, seq)) %>%
    mutate(ASV_new = paste("ASV", i, sep=""))
  
  # Add to new.df
  new.df <- rbind(new.df, tempdf)
  # print(new.df)
  
  # Remove sequences already identified
  allseq <- allseq[!allseq %in% tempdf$Sequence]
  df <- df %>% filter(!Sequence %in% tempdf$Sequence)
  # print(head(df))
  # cat("\n")
  # cat("Seq vector:", allseq, "\n\n")
  
  i=i+1
}

head(new.df)
# Common ASVs were correctly identified.

# Keep only 1 sequence per ASV (the shortest one)
new.df %>%
  group_by(ASV_new) %>%
  filter(Sequence == Sequence[which.min(nchar(Sequence))]) %>%
  select(-ASV)

# See common ASVs between datasets (authors)
new.df %>%
  select(author, ASV_new)
```


## 2. Real data

First, we will build the taxonomic table from all datasets.

```{r tax-table}
# BUILD TAXONOMIC TABLE WITH ALL DATASSETS

taxtable <- lapply(datasets, function(physeq){
  
  taxa_names(physeq) <- refseq(physeq)
  tax_table(physeq) %>%
    as.data.frame() %>%
    mutate(author = unique(sample_data(physeq)$author)) %>%
    mutate(vregion = unique(sample_data(physeq)$variable_region)) %>%
    mutate(sequence = rownames(tax_table(physeq)))
  
}) %>%
  bind_rows() %>%
  arrange(nchar(sequence))

print(nrow(taxtable)) # 49,619 ASVs
```


Now we can identify common ASVs just like we did with the mock data.

```{r merge-ASV, echo=TRUE, eval=FALSE}
# MERGE COMMON ASVs

taxtable.new <- data.frame(matrix(ncol=ncol(taxtable)+1, nrow=0))
colnames(taxtable.new) <- c(colnames(taxtable), "ASV")

allseq <- taxtable$sequence
i=1

# Identify ASVs with same sequence and give them same ASV reference
while(length(allseq) !=0 ){
  
  seq <- allseq[1]
  
  # Subset df by sequence
  tempdf <- taxtable %>%
    filter(str_detect(sequence, seq)) %>%
    mutate(ASV = paste("ASV", i, sep=""))
  
  # Add to new.df
  taxtable.new <- rbind(taxtable.new, tempdf)

  # Remove sequences already identified
  allseq <- allseq[!allseq %in% tempdf$sequence]
  taxtable <- taxtable %>% filter(!sequence %in% tempdf$sequence)
  
  # Follow progress of computation
  if(length(allseq)%%100==0){ cat(length(allseq), "-", nrow(taxtable), "\n") }
  
  i=i+1
}


# Save
# saveRDS(taxtable.new, "~/Projects/IBS_Meta-analysis_16S/data/analysis-combined/01_Merge-Datasets/taxtable_merged.rds")
```


Let's do a few sanity checks.

```{r sanity-check}
# Import saved taxtable.new
# taxtable.new <- readRDS(file.path(path, "data/analysis-combined/01_Merge-Datasets/taxtable_merged.rds"))

# check size of taxtable.new
print(nrow(taxtable.new)) # 51,132 ASVs
# we have 1513 rows more than the original table, why?
table(taxtable.new$sequence %in% taxtable$sequence)
# all the sequences in new table can be found in the original table. That must mean duplicates must have been created.

# check that the shortest sequence of each ASV can be found in the other sequences
taxtable.new %>%
  group_by(ASV) %>%
  mutate(verif = str_detect(string=sequence, pattern=sequence[which.min(nchar(sequence))])) %>%
  ungroup() %>%
  count(verif)
# Only TRUEs!! =)
taxtable.new %>%
  group_by(ASV) %>%
  filter(sequence != sequence[which.min(nchar(sequence))]) %>%
  mutate(verif = str_detect(string=sequence, pattern=sequence[which.min(nchar(sequence))])) %>%
  ungroup() %>%
  count(verif)

# check that ASVs with several sequences have the same taxa assigned to them
test <- taxtable.new %>%
  group_by(ASV) %>%
  # if several sequences for the ASV, replace NA values by the known Genus of other sequences
  fill(Genus, .direction="downup") %>%
  filter(n_distinct(Class)>1) %>%
  arrange(nchar(sequence)) %>%
  arrange(ASV)

# Keep only 1 sequence per ASV (the shortest one)
taxtable.new %>%
  group_by(ASV) %>%
  filter(sequence == sequence[which.min(nchar(sequence))])


# See common ASVs between datasets (authors)
test <- taxtable.new %>%
  select(author, ASV)
```


Now we can infer some taxa.

```{r}
# Import saved taxtable.new
taxtable.new <- readRDS(file.path(path, "data/analysis-combined/01_Merge-Datasets/taxtable_merged.rds"))


taxtable.new <- taxtable.new %>%
  group_by(ASV) %>%
  # if several sequences for the ASV, replace NA values by the known Genus of other sequences
  # fill(Class, .direction="downup") %>%
  fill(Order, .direction="downup") %>%
  fill(Family, .direction="downup") %>%
  fill(Genus, .direction="downup")

# Sanity check
taxtable.new %>%
  group_by(ASV) %>%
  filter(n_distinct(Class)>1) %>%
  arrange(nchar(sequence)) %>%
  arrange(ASV) %>%
  relocate(ASV)
```



################
# VENN DIAGRAM #
################

```{r venn-diagram}
# Libraries
library(VennDiagram)
library(RColorBrewer)

# Build lists
authors.V1_V2 <- c("LoPresti", "Fukui", "Zeber-Lubecka")
authors.V3_V4 <- c("LoPresti", "Labus", "Zhuang", "Hugerth", "Zeber-Lubecka")
authors.V4 <- c("Pozuelo", "Zhu", "Nagel", "Hugerth", "Zhuang")

commonASV <- function(x){
  temp <- list()
  for(author in x){
    temp[[author]] <- taxtable.new[taxtable.new$author == author, "ASV"]
  }
  return(temp)
}


venn.V1_V2 <- commonASV(authors.V1_V2)
venn.V3_V4 <- commonASV(authors.V3_V4)
venn.V4 <- commonASV(authors.V4)

# Plot
plotVenn <- function(vennList, file.name, vregion){
  cat <- data.frame(authors = c("LoPresti", "Labus", "Fukui", "Zhuang", "Hugerth", "Pozuelo", "Zhu", "Nagel", "Zeber-Lubecka"),
                   vregion = c("V1-V3", "V3-V5", "V1-V2", "V3-V4", "V3-V4", "V4", "V4", "V4", "V2-V9")) %>%
    unite("name", authors:vregion, sep=" (", remove=FALSE)
  cat$name <- str_c(cat$name, ")")
  
  venn.diagram(
          x = vennList,
          category.names = cat[cat$authors %in% names(vennList), ]$name,
          filename = paste('./plots/01_Merge-Datasets/', file.name, '.png', sep=""),
          output=FALSE,
          main=paste("Datasets sequencing", vregion, "regions"),
          
          # Output features
          imagetype="png",
          height = 1000,
          width = 1000,
          resolution = 300,
          compression = "lzw",
          
          # Circles
          lwd = 2,
          lty = 'blank',
          fill = brewer.pal(length(vennList), "Pastel2"),
          
          # Numbers
          cex = .6,
          
          # Set names
          cat.cex = .8,
          cat.fontface = "bold",
          cat.default.pos = "outer"
  )
}

plotVenn(venn.V1_V2, "V1-V2", "V1-V2")
plotVenn(venn.V3_V4, "V3-V4", "V3-V4")
plotVenn(venn.V4, "V4", "V4")
```


```{r}
vennOnDemand <- function(author_list, filename, v.region){
  
  # Get the common ASVs between these authors
  venn.authors <- commonASV(author_list)
  
  # Plot vennDiagram
  plotVenn(venn.authors, filename, v.region)
  
}

vennOnDemand(c("LoPresti", "Pozuelo", "Nagel"), "test", "V3-V5")
```


GGupset
```{r}
library(ggupset)

test <- taxtable.new %>%
  select(c(author, ASV)) %>%
  group_by(ASV) %>%
  summarize(Datasets = list(unique(author))) %>%
  filter(lengths(Datasets)>1)

jpeg("./plots/01_Merge-Datasets/ggupset.jpg", width=3000, height=2000, res=400)
ggplot(test, aes(x=Datasets))+
    geom_bar() +
    scale_x_upset()+
  labs(y="# of common ASVs")
dev.off()

```




##########################
# MERGE PHYLOSEQ OBJECTS #
##########################

```{r}
taxtable.new
```


