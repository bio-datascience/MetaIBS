---
title: "Predictive_model"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: inline
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE,
                      root.dir = "/Users/enigma/Desktop/Munich/Praktikum/Data/Rproject_COMBINE/PREDICTION/")
```


```{r library}
library(dada2) # manage fastq file
library(ShortRead) # manage fastq file
library(Biostrings) # to manage dna sequences as strings
library(seqTools) # analyse read length in fastq file
library(phyloseq) # for phyloseq object
library(ggplot2) # for plots
library(ggrepel)
library(reshape2)
library(data.table)
library(plyr)
library(dplyr)
library("doParallel")
library("foreach")
library("DECIPHER") # for phylogenetic tree
library("phangorn")
library("plotly") # plot 3D
library("microbiome") # for centered log-ratio
library("coda") # Aitchison distance
library("coda.base") # Aitchison distance
library("vegan") # NMDS
library(pheatmap) # for heat map
library(RColorBrewer)
library(glmnet) # for prediction
library(gtools) # for combinations
library(tidyverse)
library(caret) # for randomForest
library(randomForest) # for randomForest
library(e1071) # for randomForest
```



# IMPORT DATA
```{r import-data}
# Import phyloseq object with all fecal samples with > 1000 total count per sample
physeq <- readRDS("../physeq_best_fecal.rds")
physeq

# Import metadata (disease status, author, sequencing technology for each sample)
metadata <- readRDS('../mat_col.rds')
```


# DEFINE FUNCTIONS

## Agglomeration of taxa

This function agglomerates a phyloseq object at all taxonomic levels, and returns a list containing the melted dataframes for each taxonomic level.

```{r agglomeration, eval = FALSE, echo = TRUE}
Agglomerate <- function(phyloseq_obj){
  
  print("PHYLUM")
  phylum.agg <- phyloseq_obj %>%
    tax_glom(taxrank = "Phylum") %>%                     # agglomerate at phylum level
    transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
    psmelt()                                             # Melt to long format
  
  print("CLASS")
  class.agg <- phyloseq_obj %>%
    tax_glom(taxrank = "Class") %>%                     # agglomerate at class level
    transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
    psmelt()                                             # Melt to long format
  
  print("ORDER")
  order.agg <- phyloseq_obj %>%
    tax_glom(taxrank = "Order") %>%                     # agglomerate at order level
    transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
    psmelt()                                             # Melt to long format
  
  print("FAMILY")
  family.agg <- phyloseq_obj %>%
    tax_glom(taxrank = "Family") %>%                     # agglomerate at family level
    transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
    psmelt()                                             # Melt to long format
  
  print("GENUS")
  genus.agg <- phyloseq_obj %>%
    tax_glom(taxrank = "Genus") %>%                     # agglomerate at genus level
    transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
    psmelt()                                             # Melt to long format
  
  #print("SPECIES")
  #species.agg <- phyloseq_obj %>%
  #  tax_glom(taxrank = "Species") %>%                     # agglomerate at species level
  #  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  #  psmelt()                                             # Melt to long format
  
  print("END")
  agg <- list("Phylum" = phylum.agg, "Class" = class.agg, "Order" = order.agg,
              "Family" = family.agg, "Genus" = genus.agg)
  
  return(agg)
}

# Call function
taxa.agg <- Agglomerate(phyloseq_obj = physeq)

# Save
#saveRDS(taxa.agg, "AgglomeratedTaxa.rds")
```

```{r import-agglomeration, echo = FALSE}
taxa.agg <- readRDS("AgglomeratedTaxa.rds")
```



## Keep most abundant taxa

The _TaxaAbundanceThreshold_ function will allow to apply a threshold to keep the most abundant taxa. As input, we give the melted dataframe obtained by agglomerating the taxa, and also give a threshold (e.g. taxa must be present in at least 10% of samples). The function returns a matrix with (most abundant) taxa as rows and samples as columns.

```{r remove-low-abundant-taxa}
GetMatrix <- function(TaxLevel, tax.agg){
 
  if (TaxLevel == "Phylum"){
    print("PHYLUM")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Phylum ~ Sample, value.var = 'Abundance') # transform into matrix
  } else if (TaxLevel == "Class"){
    print("CLASS")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Class ~ Sample, value.var = 'Abundance') # transform into matrix
  } else if(TaxLevel == "Order"){
    print("ORDER")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Order ~ Sample, value.var = 'Abundance') # transform into matrix
  } else if(TaxLevel == "Family"){
    print("FAMILY")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Family ~ Sample, value.var = 'Abundance') # transform into matrix
  } else if(TaxLevel == "Genus"){
    print("GENUS")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Genus ~ Sample, value.var = 'Abundance') # transform into matrix
  } else if(TaxLevel == "Species"){
    print("SPECIES")
    taxaTable <- acast(tax.agg[tax.agg$author != "Ringel-Kulka",],
                        Species ~ Sample, value.var = 'Abundance') # transform into matrix
  }
  
  return(taxaTable)
}


TaxaAbundanceThreshold <- function(taxa_agg_list, threshold, nbsamples){
  
  # Taxonomic Levels
  cat("Taxonomic levels:", names(taxa_agg_list), "\n")
  
  # This list will contain matrix of log-ratios, at every taxonomic level
  taxaTable.list <- list()
  
  sampleThreshold <- (1-(threshold/100))*nbsamples # maximal nb of samples that can contain 0 counts
  cat("Threshold: taxa will be kept only if they have 0 counts in", sampleThreshold, "samples or less. \n")
  
  # Iterate, taxonomic level per taxonomic level
  for (TaxLevel in names(taxa_agg_list)) {
    cat("\n\n+ ------------------------------ + \n")
    cat("+ TAXONOMIC LEVEL:", TaxLevel, "+ \n")
    
    # Initialize variables
    tax.agg <- NULL
    taxaTable <- NULL
    zeroTable <- NULL
    
    # Transform agglomerated table into matrix (taxa as rows / samples as columns)
    tax.agg <- taxa_agg_list[[TaxLevel]] # get the agglomerated table
    #cat("  Nb of columns in agglomerated table:", ncol(tax.agg), "\n")
    
    taxaTable <- GetMatrix(TaxLevel = TaxLevel, tax.agg = tax.agg)
    cat("  Dimensions matrix (taxa as rows / samples as columns):", dim(taxaTable), "\n")
    
    # Look at abundance of taxa (nb of zero counts in each taxa) to see which ones will be discarded
    zeroTable <- as.data.frame(rowSums(taxaTable == 0)) # nb of zero counts per taxa
    zeroTable$taxa <- rownames(zeroTable)
    colnames(zeroTable) <- c("NbZeroCounts", "taxa")
    zeroTable$threshold <- paste0("Taxa present in >", threshold, "% of samples")
    zeroTable[zeroTable$NbZeroCounts > sampleThreshold, "threshold"] <- "Taxa removed"
    
    ggplot(zeroTable, aes(x = reorder(taxa, -NbZeroCounts), y = NbZeroCounts, fill = threshold))+
      geom_bar(stat = "identity")+
      coord_flip()+
      theme_bw()+
      scale_fill_manual(values = c("grey", "#CC0033"))+
      labs(x = "Taxa")
    
    # Subset the matrix (remove low-abundant taxa)
    cat("  ...Removing taxa that are not present in at least", threshold, "% of the samples... \n")
    taxaTable <- taxaTable[rowSums(taxaTable == 0) <= sampleThreshold, ]
    cat("  Dimensions new matrix:", dim(taxaTable), "\n")
    
    # Look at number of zero counts
    cat("  Number of 0 counts:", table(taxaTable == 0)[2], "versus non-0 counts:", table(taxaTable == 0)[1], "\n")
    cat("  ...Replacing 0 counts by half the lowest count... \n")
    taxaTable[taxaTable == 0] <- 1e-5 # add pseudocounts, otherwise can't compute ratios by dividing by 0
    
    # Add to list
    taxaTable.list[[TaxLevel]] <- taxaTable
  }
  
  return(taxaTable.list)
}
```


## Log-ratios between phyla
This function takes as input a matrix of relative abundances of taxa across samples (taxa as rows and samples as columns) and returns the log-ratios between all taxa (samples in rows and log-ratios in columns), performing all combinations.

```{r log-ratios}
#________________________
# LOG-RATIOS

LogRatios <- function(abundanceTable){
  
  # Get combinations between all phyla
  comb <- combinations(nrow(abundanceTable), 2, rownames(abundanceTable), repeats.allowed = FALSE)
  comb <- as.data.frame(comb)
  comb[,3] <- paste0(comb[,1], "/", comb[,2])
  #cat("First 5 combinations:\n")
  comb[1:5,]
  
  cat("Number of combinations:", nrow(comb), "\n")

  # Compute the ratios
  ratios <- as.data.frame(abundanceTable)
  test <- ratios[1:2,1:2] # for later sanity check
  
  ratios[ comb[,3] ,] <- mapply(function(x, y) log2(x/y), # compute the log ratio
                                abundanceTable[ as.character(comb[,1]) ,], # between first column
                                abundanceTable[ as.character(comb[,2]) ,]) # and second column of all combinations

  ratios <- ratios[-c(1:nrow(abundanceTable)),] # remove first x rows that are not ratios (it is simply the phyla)
  cat("Sanity check: log-ratio is", log2(test[1,1]/test[2,1]),
      "and the corresponding value in the log-ratio table is", ratios[1,1], "\n")
  cat("Sanity check2: log-ratio is", log2(test[1,2]/test[2,2]),
      "and the corresponding value in the log-ratio table is", ratios[1,2], "\n") # sanity check
  
  ratios <- t(ratios) # Get the observations (samples) in rows, and predictors (ratios) in columns
  cat("We have", dim(ratios)[1], "samples and", dim(ratios)[2], "predictors (log-ratios) \n")

  # Show the ratios table
  #cat("Head of the log-ratios table:")
  as.data.frame(head(ratios[, 1:5]))
  
  return(ratios)
}
```


## Authors/dataset predictors
This function takes a metadata dataframe as input (e.g. the original metadata dataframe containing the author and seqTech information, but subsetted to contain only samples for training the model), and returns authors as predictive variables (0 or 1 for each author).

```{r authors-predictors}
#________________________
# AUTHORS
authorsTable <- function(metadataDF){
  
  authorsDF <- as.data.frame(metadataDF[,'author'])
  rownames(authorsDF) <- rownames(metadataDF)
  colnames(authorsDF) <- "author"
  
  # Get authors in columns
  #authorsDF$RingelKulka <- 0
  authorsDF$Labus <- 0
  authorsDF$LoPresti <- 0
  authorsDF$Pozuelo <- 0
  authorsDF$Zhuang <- 0
  authorsDF$Zhu <- 0
  authorsDF$ZeberLubecka <- 0
  
  # Code the authors as predictors (add 1)
  #authors[authors$author == 'Ringel-Kulka','RingelKulka'] <- 1
  authorsDF[authorsDF$author == 'Labus','Labus'] <- 1
  authorsDF[authorsDF$author == 'LoPresti','LoPresti'] <- 1
  authorsDF[authorsDF$author == 'Pozuelo','Pozuelo'] <- 1
  authorsDF[authorsDF$author == 'Zhuang','Zhuang'] <- 1
  authorsDF[authorsDF$author == 'Zhu','Zhu'] <- 1
  authorsDF[authorsDF$author == 'Zeber-Lubecka','ZeberLubecka'] <- 1
  
  return(authorsDF[,-1])
}
```


## Sequencing technology predictors
This function takes a metadata dataframe as input (e.g. the original metadata dataframe containing the author and seqTech information, but subsetted to contain only samples for training the model), and returns sequencing technology as predictive variables (0 or 1 for each seqTech).
```{r seqTech-predictors}
#________________________
# SEQENCING TECH

seqtechTable <- function(metadataDF){
  
  seqTech <- as.data.frame(metadataDF[,'author'])
  rownames(seqTech) <- rownames(metadataDF)
  colnames(seqTech) <- 'author'
  
  # Get sequencing technologies into columns
  seqTech$pyroseq <- 0
  seqTech$MiSeqSingle <- 0
  seqTech$MiSeqPaired <- 0
  seqTech$IonTorrent <- 0
  
  # Add 1 (code the seq tech predictors)
  #seqTech[seqTech$author == 'Ringel-Kulka','pyroseq'] <- 1
  seqTech[seqTech$author == 'Labus','pyroseq'] <- 1
  seqTech[seqTech$author == 'LoPresti','pyroseq'] <- 1
  seqTech[seqTech$author == 'Pozuelo','MiSeqSingle'] <- 1
  seqTech[seqTech$author == 'Zhuang','MiSeqPaired'] <- 1
  seqTech[seqTech$author == 'Zhu','MiSeqPaired'] <- 1
  seqTech[seqTech$author == 'Zeber-Lubecka','IonTorrent'] <- 1
  
  return(seqTech[,-1]) # first column contains the authors
}
```


## Merge features tables

This function will merge the log-ratios dataframe with the authors DF or the seqTech DF. It can be the full DF (with all samples), or just a subset table (e.g. the training DF or the testing DF).

```{r merge-features-tables}
#________________________
# MERGE FEATURES

MergePredictors <- function(logratioDF, author, seqtech){
  
  # Get the sample names from the dataframe with log-ratios
  sample_names <- rownames(logratioDF)
  
  # If we want to use authors (cohorts) as predictors
  if (author == TRUE & seqtech == FALSE){
    # get the authors of the chosen samples coded as 0 or 1
    authorsDF <- authorsTable(metadataDF = metadata[rownames(metadata) %in% sample_names, ])
    logratioDF <- logratioDF[sample_names,] # make sure both DF have the same row order
    authorsDF <- authorsDF[sample_names,]
    cat("\n    Sanity check: same row order log-ratios and authors DF?")
    print(table(rownames(logratioDF) == rownames(authorsDF)))
    predictors <- cbind(authorsDF, logratioDF) # combine authors with ratios by matching rows
    return(predictors)
  }
  
  # If we want to use sequencing tech as predictors
  else if (author == FALSE & seqtech == TRUE){
    # get the seqTech of the chosen samples coded as 0 or 1
    seqtechDF <- seqtechTable(metadataDF = metadata[rownames(metadata) %in% sample_names, ])
    logratioDF <- logratioDF[sample_names,] # make sure both DF have the same row order
    seqtechDF <- seqtechDF[sample_names,]
    cat("\n    Sanity check: same row order log-ratios and seqTech DF?")
    print(table(rownames(logratioDF) == rownames(seqtechDF)))
    predictors <- cbind(seqtechDF, logratioDF) # combine seqTech with ratios by matching rows
    return(predictors)
  }
  
}
```


## Choose randomly samples for training & testing

This function chooses randomly 50% of samples in each cohort to use for training. As there are 3x more IBS than healthy samples in 3 datasets (Pozuelo, Zhuang, Zeber), we make sure to have about the same number of IBS and healthy samples randomly selected from each dataset. In the end, we first randomly select 80% of healthy samples in each dataset, and 50-80% of IBS samples in each dataset (as many IBS samples as healthy ones).
The remaining samples can be used as testing (also making sure we have as many IBS as healthy).

```{r random-sample-selection}
TrainTestSamples <- function(authorList){
  
  samplesToTrain <- c()
  samplesToTest <- c()
  
  # Get random sample names for the training & testing dataframes
  for (aut in authorList){
    
    # initialize variables
    df <- NULL
    hc <- NULL
    ibs <- NULL
    hc_train <- NULL
    ibs_train <- NULL
    hc_test <- NULL
    ibs_test <- NULL
    
    df <- metadata[metadata$author == aut,] # subset the metadata df by author
    hc <- rownames(df[df$host_disease == "Healthy",]) # get healthy sample names
    ibs <- rownames(df[df$host_disease == "IBS",]) # get ibs sample names
    
    # Randomly choose the healthy samples
    hc_train <- sample(hc, length(hc)*0.8) # get randomly 80% of the healthy samples for the training dataframe
    hc_test <- hc[!hc %in% hc_train] # get the remaining 20% for the testing dataframe
    cat("  Nb healthy samples chosen for training df in", aut, "dataset:", length(hc_train), "\n")
    cat("  Nb healthy samples chosen for testing df in", aut, "dataset:", length(hc_test), "\n")
    
    # Randomly choose the ibs samples
    if (aut == "Pozuelo" | aut == "Zhuang" | aut == "Zeber-Lubecka"){
      ibs_train <- sample(ibs, length(hc_train)) # get ~ as many ibs samples as healthy for training dataframe (otherwise we'll get 3x more)
      ibs_test <- sample(ibs[!ibs %in% ibs_train], length(hc_test)) # get the remaining ibs samples as testing, making sure we have as many ibs samples as healthy for the testing df
    } else {
      ibs_train <- sample(ibs, length(ibs)*0.8) # get 80% of ibs samples
      ibs_test <- ibs[!ibs %in% ibs_train] # get the remaining 20% for the testing dataframe
    }
    cat("  Nb ibs samples chosen for training df in", aut, "dataset:", length(ibs_train), "\n")
    cat("  Nb ibs samples chosen for testing df in", aut, "dataset:", length(ibs_test), "\n \n")
    
    # Add the samples to the list
    samplesToTrain <- c(samplesToTrain, hc_train, ibs_train)
    samplesToTest <- c(samplesToTest, hc_test, ibs_test)
  }
  
  # Put the sample names into a list (training and testing)
  randomSamples <- list("train" = samplesToTrain, "test" = samplesToTest)
  
  cat("** END RANDOM SAMPLING FUNCTION ** \n")
  
  return(randomSamples)
}
```


## Normalize features

We need to have all features (log-ratios of bacterial taxa) on the same scale. This function performs a mean centering so that each feature has a mean = 0, and normalizes the L2 norm of each feature to 1.

```{r normalize-features, fig.height = 5, fig.width = 5}
Normalizing <- function(df){
  #_____________________________________________
  # MEAN-CENTER
  cat("  + --------------------- \n")
  cat("  + Mean-centering \n")
  df <- scale(df, center = TRUE, scale = FALSE)
  
  #_____________________________________________
  # SCALE TO SAME L2 NORM
  cat("  + --------------------- \n")
  cat("  + Scaling all predictors to L2 norm = 1 \n")
  # remove columns filled with 0 (null predictors)
  df <- df[, !apply(df == 0, 2, all)]
  # divide each count by the L2 norm of the column (the whole predictor vector)
  df <- df / matrix(sqrt(colSums(df**2)), nrow=nrow(df), ncol=ncol(df), byrow=TRUE)
  
  #_____________________________________________
  # SANITY CHECK
  # Calculate L2 norm of all predictors
  cat("  + --------------------- \n")
  cat("  + SANITY CHECK: L2 norm of all features \n")
  print(table(apply(df, 2, function(x) sqrt(sum(x**2)))))
  
  cat("** END NORMALIZING ** \n")
  
  return (df)
}
```



## Add disease phenotype

This function takes a features table as input (e.g. training DF), and will add the disease phenotype of each sample in the first column (disease phenotype = {0;1}).

```{r add-disease-phenotype}
DiseasePhenotype <- function(df, message){
  #_____________________________________________
  # ADD THE DISEASE PHENOTYPE AS THE FIRST COLUMN
  cat("  + --------------------- \n")
  cat("  + Adding disease phenotype for", message, "\n")
  # get the disease status of the samples from the original metadata table
  diseaseStatus <- as.data.frame(metadata[rownames(metadata) %in% rownames(df), "host_disease"])
  rownames(diseaseStatus) <- rownames(metadata[rownames(metadata) %in% rownames(df), ])
  colnames(diseaseStatus) <- 'disease'
  diseaseStatus$disease <- as.character(diseaseStatus$disease)
  # replace disease phenotype by 0 or 1
  diseaseStatus[diseaseStatus$disease == "Healthy",] <- 0
  diseaseStatus[diseaseStatus$disease == "IBS",] <- 1
  # make sure the order of rownames is the same in the predictors DF and disease phenotype DF
  df <- df[rownames(diseaseStatus),]
  # sanity check that the dataframe with predictors and the disease phenotype df have the same samples (rownames)
  cat("  + Predictors df and Disease phenotype df have same rownames/samples?")
  print(table(rownames(diseaseStatus) == rownames(df)))
  # merge the disease phenotype df and the predictors df
  df <- cbind(diseaseStatus, df)
  
  #_____________________________________________
  # CORRECT FORMATING FOR GLMNET
  df <- data.matrix(df)
  
  cat("** END DISEASE PHENOTYPE ** \n")
  
  return (df)
}
```




## Integrating all functions to get training & testing DF

This function takes as input the dataframe with log-ratios (samples as rows, log-ratios as columns) and will: \n
(1) normalize the log-ratios (mean-centering & scaling) \n
(2) randomly split it into training (~50%) and testing (~15%) dataframes (can't do 80-20 because too many IBS samples compared to healthy). \n
(3) add the authors or seqTech as predictors (binary predictors {0,1}), if we have several cohorts \n
(4) add the disease phenotype of the samples as the first column \n

This function returns the training & testing DF ready for the predictive model.

```{r sampling-function}
Sampling <- function(logratioDF, authorList){
  
  #_________________________________________________
  # NORMALIZE THE LOG-RATIOS

  cat("############################## \n")
  cat("# 1 - NORMALIZING LOG-RATIOS # \n")
  cat("############################## \n")
  
  logratioDF <- Normalizing(df = logratioDF)
  
  cat("\n")
  cat("______________________ \n")
  cat("\n \n")
  
  #_________________________________________________
  # CHOOSE RANDOMLY SAMPLES FOR TRANING AND TESTING
  cat("###################################################### \n")
  cat("# 2 - SPLIT FEATURES TABLE INTO TRAINING AND TESTING # \n")
  cat("###################################################### \n")
  
  # Call the function to get random samples for training and testing
  cat("** => CALLING FUNCTION TO CHOOSE RANDOMLY TRAINING/TESTING SAMPLES ** \n")
  randomSamples <- TrainTestSamples(authorList = authorList)
  
  # Sanity check
  print("Is there common samples between the chosen samples for training and testing?")
  print(table(randomSamples$train %in% randomSamples$test))
  
  # See what's the proportion of samples which are found in the training dataframe
  cat("We have", length(randomSamples$train)*100/nrow(logratioDF), "% of the samples in the training dataframe, and",
      length(randomSamples$test)*100/nrow(logratioDF), "% of the samples in the testing dataframe \n")
  
  # Split features table into training & testing
  train.df <- logratioDF[rownames(logratioDF) %in% randomSamples$train, ]
  test.df <- logratioDF[rownames(logratioDF) %in% randomSamples$test, ]
  
  cat("Dimensions of training df (samples as rows and log-ratios as columns):")
  print(dim(train.df))
  cat("Dimensions of testing df (samples as rows and log-ratios as columns):")
  print(dim(test.df))
  
  cat("\n")
  cat("______________________ \n")
  cat("\n \n")
  
  
  #_________________________________________________
  # ADD AUTHORS OR SEQTECH AS PREDICTIVE FEATURES
  
  # If we are building the training/testing df for 1 cohort, we only need to add the disease phenotype
  
  if(length(authorList) == 1){
    
    cat("############################# \n")
    cat("# 3 - ADD DISEASE PHENOTYPE # \n")
    cat("############################# \n")
    
    train.df <- DiseasePhenotype(df = train.df, message = paste0("train set of ", authorList, " dataset"))
    test.df <- DiseasePhenotype(df = test.df, message = paste0("test set of ", authorList, " dataset"))
    
  }
  
  # If we are building the training/testing df for 2 cohorts or more, we'll add authors/seqTech as predictive features
  else if (length(authorList) > 1){
    
    cat("############################## \n")
    cat("# 3 - ADD AUTHORS OR SEQTECH # \n")
    cat("############################## \n")
    
    # Add authors
    cat("  + --------------------- \n")
    cat("  + Adding authors predictors \n")
    train.authors <- MergePredictors(logratioDF = train.df, author = TRUE, seqtech = FALSE)
    test.authors <- MergePredictors(logratioDF = test.df, author = TRUE, seqtech = FALSE)
    
    # Add seqTech
    cat("  + --------------------- \n")
    cat("  + Adding seqTech predictors \n")
    train.seqTech <- MergePredictors(logratioDF = train.df, author = FALSE, seqtech = TRUE)
    test.seqTech <- MergePredictors(logratioDF = test.df, author = FALSE, seqtech = TRUE)
    
    cat("\n")
    cat("______________________ \n")
    cat("\n \n")
    
    cat("############################# \n")
    cat("# 4 - ADD DISEASE PHENOTYPE # \n")
    cat("############################# \n")
    
    train.authors <- DiseasePhenotype(df = train.authors, message = "training df with authors")
    test.authors <- DiseasePhenotype(df = test.authors, message = "testing df with authors")
    train.seqTech <- DiseasePhenotype(df = train.seqTech, message = "training df with seqTech")
    test.seqTech <- DiseasePhenotype(df = test.seqTech, message = "testing df with seqTech")
  }  

  
  cat("\n")
  cat("______________________ \n")
  cat("\n \n")
  
  
  #_________________________________________________
  # SANITY CHECKS
  
  cat("##################### \n")
  cat("# 5 - SANITY CHECKS # \n")
  cat("##################### \n")
  
  # If we are building the training/testing df only for 1 cohort
  if(length(authorList) == 1){
    
    # Sanity check: number of IBS and healthy samples in each df
    cat("SANITY CHECK: number of IBS and healthy samples... \n")
    cat("...in training df:")
    print(table(train.df[,1]))
    cat("\n ...in testing df:")
    print(table(test.df[,1]))
    cat("\n")
    
    # Sanity checks
    cat("SANITY CHECK: dimensions of training/testing df (samples as rows & predictors as columns... \n")
    cat("...in training df: \n")
    print(dim(train.df))
    cat("...in testing df: \n")
    print(dim(test.df))
  }
  
  # If we are building the training/testing df for 2 cohorts or more
  else if (length(authorList) > 1){

    # Sanity check: number of IBS and healthy samples in each df
    cat("SANITY CHECK: number of IBS and healthy samples... \n")
    cat("...in training df with authors:")
    print(table(train.authors[,1])) # 111 predictors
    cat("\n ...in testing df with authors:")
    print(table(test.authors[,1])) # 111 predictors
    cat("\n ...in training df with seqTech:")
    print(table(train.seqTech[,1])) # 109 predictors
    cat("\n ...in testing df with seqTech:")
    print(table(test.seqTech[,1])) # 109 predictors
    
    cat("\n")
    
    # Sanity checks
    cat("SANITY CHECK: dimensions of training/testing df (samples as rows & predictors as columns... \n")
    cat("...in training df with authors as predictors: \n")
    print(dim(train.authors)) # 275 samples and 112 columns (105 ratios + 6 authors + 1 disease phenotype)
    cat("...in testing df with authors as predictors: \n")
    print(dim(test.authors)) # 74 rows (samples) and 112 columns (105 ratios + 6 authors + 1 disease phenotype)
    
    cat("...in training df with seqTech as predictors: \n")
    print(dim(train.seqTech)) # 275 samples and 110 columns (105 ratios + 4 seqTech + 1 disease phenotype)
    cat("...in testing df with seqTech as predictors: \n")
    print(dim(test.seqTech)) # 74 rows (samples) and 110 columns (105 ratios + 4 seqTech + 1 disease phenotype)
  }
    
  
  #_________________________________________________
  # RETURN DATA MATRICES
  
  # If we are building the training/testing df only for 1 cohort
  if(length(authorList) == 1){
    return_matrices <- list("Train" = train.df, "Test" = test.df)
  }
  
  # If we are building the training/testing df for 2 cohorts or more
  else if (length(authorList) > 1){
    return_matrices <- list("TrainAut" = train.authors, "TestAut" = test.authors,
                            "TrainSeq" = train.seqTech, "TestSeq" = test.seqTech)
  }
  
  return(return_matrices)
}
```


\n \n

_____________________________________________________________________________________
_____________________________________________________________________________________

\n \n

# BUILD FEATURES TABLES

## Data pre-processing

First, we'll create matrix with samples as columns and taxa as rows. Only the taxa present in at least 10% of samples will be kept. 0 counts will then be replaced by pseudocounts (half the lowest count), to be able to calculate later log-ratios. The TaxaAbundanceThreshold function allows to return a list with this matrix for each taxonomic level (Phylum => Species).

```{r taxa-preprocessing}
# Get matrix for all taxonomic levels
taxaTable.list <- TaxaAbundanceThreshold(taxa_agg_list = taxa.agg, threshold = 10, nbsamples = 530)

# Look at phylum table
as.data.frame(taxaTable.list$Phylum[, 1:5])

# Look at family table
as.data.frame(taxaTable.list$Family[, 1:5])

## ISSUE WITH SPECIES!!
```

Second, we will transform these matrix into log-ratios between all taxa.

```{r obtain-log-ratios}
ratios.phyla <- LogRatios(taxaTable.list$Phylum) # phylum
ratios.class <- LogRatios(taxaTable.list$Class) # class
ratios.order <- LogRatios(taxaTable.list$Order) # order
ratios.family <- LogRatios(taxaTable.list$Family) # family
ratios.genus <- LogRatios(taxaTable.list$Genus) # genus
```


## Obtain features tables

Call the functions to obtain the training & testing dataframes by sampling randomly ~50% of samples and 15% of samples, respectively.

### Phylum level
```{r phylum-features}
# Call the function
author_list <- c("Labus", "LoPresti", "Pozuelo", "Zhuang", "Zhu", "Zeber-Lubecka") # authors we want to include
phyla.allDF <- Sampling(logratioDF = ratios.phyla, authorList = author_list)

# Look at how the training dataframes with authors or seqTech look like
as.data.frame(phyla.allDF$TrainAut[, 1:20])
as.data.frame(phyla.allDF$TrainSeq[, 1:20])

# Sanity check: look at distribution of log-ratios
hist(phyla.allDF$TrainAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Training DF")
hist(phyla.allDF$TestAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Testing DF")
boxplot(phyla.allDF$TrainAut[,-c(1:7)], outline = FALSE, main = "Training DF")
boxplot(phyla.allDF$TestAut[,-c(1:7)], outline = FALSE, main = "Testing DF")
```

### Class level
```{r class-features, results = 'hide', fig.width = 4, fig.height = 3}
# Call the function
class.allDF <- Sampling(logratioDF = ratios.class, authorList = author_list)

# Look at how the training & testing dataframes with authors look like
as.data.frame(class.allDF$TrainAut[, 1:20])
as.data.frame(class.allDF$TestAut[, 1:20])

# Sanity check: look at distribution of log-ratios
hist(class.allDF$TrainAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Training DF")
hist(class.allDF$TestAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Testing DF")
boxplot(class.allDF$TrainAut[,-c(1:7)], outline = FALSE, main = "Training DF")
boxplot(class.allDF$TestAut[,-c(1:7)], outline = FALSE, main = "Testing DF")
```

### Order level
```{r order-features, results = 'hide', fig.width = 4, fig.height = 3}
# Call the function
order.allDF <- Sampling(logratioDF = ratios.order, authorList = author_list)

# Look at how the training dataframes with authors or seqTech look like
as.data.frame(order.allDF$TrainAut[, 1:20])
as.data.frame(order.allDF$TestAut[, 1:20])

# Sanity check: look at distribution of log-ratios
hist(order.allDF$TrainAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Training DF")
hist(order.allDF$TestAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Testing DF")
boxplot(order.allDF$TrainAut[,-c(1:7)], outline = FALSE, main = "Training DF")
boxplot(order.allDF$TestAut[,-c(1:7)], outline = FALSE, main = "Testing DF")
```

### Family level

```{r family-features, results = 'hide', fig.width = 4, fig.height = 3}
# Call the function
family.allDF <- Sampling(logratioDF = ratios.family, authorList = author_list)

# Look at how the training dataframes with authors or seqTech look like
as.data.frame(family.allDF$TrainAut[, 1:20])
as.data.frame(family.allDF$TestAut[, 1:20])

# Sanity check: look at distribution of log-ratios
hist(family.allDF$TrainAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Training DF")
hist(family.allDF$TestAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Testing DF")
boxplot(family.allDF$TrainAut[,-c(1:7)], outline = FALSE, main = "Training DF")
boxplot(family.allDF$TestAut[,-c(1:7)], outline = FALSE, main = "Testing DF")
```

### Genus level

```{r genus-features, results = 'hide', fig.width = 4, fig.height = 3}
# Call the function
genus.allDF <- Sampling(logratioDF = ratios.genus, authorList = author_list)

# Look at how the training dataframes with authors or seqTech look like
as.data.frame(genus.allDF$TrainAut[, 1:20])
as.data.frame(genus.allDF$TestAut[, 1:20])

# Sanity check: look at distribution of log-ratios
hist(genus.allDF$TrainAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Training DF")
hist(genus.allDF$TestAut[,-c(1:7)], breaks = 100, xlab = "Values of log-ratios", main = "Testing DF")
boxplot(genus.allDF$TrainAut[,-c(1:7)], outline = FALSE, main = "Training DF")
boxplot(genus.allDF$TestAut[,-c(1:7)], outline = FALSE, main = "Testing DF")
```


\n \n
_____________________________________________________________________________________
_____________________________________________________________________________________
\n \n


# SPARSE LOGISTIC REGRESSION MODEL

## 1 - DEFINE FUNCTION FOR SPARSE LOGISTIC REGRESSION MODEL

This function will run the model and return the accuracy of the model on the training & testing df. It also returns the plot showing the beta coefficient of the predictive features.

```{r sparse-logistic-regression}
LogisticRegression <- function(train.df, test.df, alpha, lambda, standardize){
  
  #_____________________________________________
  # BUILD MODEL
  
  model <- glmnet(x = train.df[, -1],
                  y = train.df[, 1], # first column is the disease phenotype
                  alpha = alpha, standardize = standardize,
                  family = "binomial", type.measure = "class",
                  lambda = lambda)

  # Build DF with the coefficients of the predictors
  coefs <- data.frame(predictors = colnames(train.df)[-1], 
                      beta = as.vector(model$beta), 
                      arbitrary_emphasis = as.factor(ifelse(abs(model$beta) > 1, "interesting", "other"))) 
  # arbitrary_emphasis: plot |beta| > 1 in a different colour
  
  # make the barplot with all predictors and their beta value
  coefs.plot <- ggplot(data = coefs[coefs$beta != 0, ],
                       aes(x = reorder(predictors, -beta), y = beta, fill = arbitrary_emphasis)) +
                geom_bar(stat="identity", col = NA) +
                xlab("") +
                guides(fill=FALSE)+
                geom_hline(yintercept = 0)+
                coord_flip()+
                theme_bw()
  
  #_____________________________________________
  # TEST MODEL
  
  # Try the predictive model on the TRAINING dataframe
  trainPredicted <- model %>% predict(newx = train.df[, -1], type = "class")

  # Model accuracy
  cat("The model is", mean(trainPredicted == train.df[, 1])*100,
      "% accurate on the TRAINING DATAFRAME, considering that the training dataframe contains",
      length(train.df[train.df[,1] == "1",1])*100/length(train.df[,1]), "% of IBS samples. \n \n")

  # Try the predictive model on the TESTING dataframe (still untouched)
  testPredicted <- model %>% predict(newx = test.df[, -1], type = "class")
  
  # MODEL ACCURACY
  cat("The model is", mean(testPredicted == test.df[, 1])*100,
      "% accurate on the TESTING DATAFRAME, considering that the testing dataframe contains",
      length(test.df[test.df[,1] == "1",1])*100/length(test.df[,1]), "% of IBS samples. \n")
  
  return(list("betaPlot" = coefs.plot, "model" = model))
  
}
```


## 2 - RUN SPARSE LOGISTIC REGRESSION (WITH AUTHORS)
(1) Look at the misclassification error depending on the tuning parameter lambda with a 10-fold cross-validation, using the authors + log-ratios between taxa as potential predictors.
(2) Build the model with the lambda.1se (except for phylum level, prediction is too bad) & measure accuracy on training and testing dataframes.
(3) Repeat for all taxonomic levels.

### Phylum level
```{r phyla-authors-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION
lambdas_to_try <- 10^seq(-5, 0, length.out = 100)


#phyla.allDF <- Sampling(logratioDF = ratios.phyla, authorList = author_list) # to re-pool samples into training & testing

set.seed(123)
cv.phy.authors <- cv.glmnet(x = phyla.allDF$TrainAut[,-1],
                            y = phyla.allDF$TrainAut[,1], # first column is disease
                            alpha = 1, standardize = TRUE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.phy.authors, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.phy.authors <- LogisticRegression(train.df = phyla.allDF$TrainAut, test.df = phyla.allDF$TestAut,
                                        alpha = 1, lambda = cv.phy.authors$lambda.min,
                                        standardize = TRUE)

model.phy.authors$betaPlot
```

### Class level
```{r class-authors-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#class.allDF <- Sampling(logratioDF = ratios.class, authorList = author_list) # to re-pool the samples
#table(test %in% rownames(class.allDF$TrainAut))

#set.seed(123)
cv.class.authors <- cv.glmnet(x = class.allDF$TrainAut[,-1],
                              y = class.allDF$TrainAut[,1], # first column is disease
                              alpha = 0.5, standardize = FALSE,
                              family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.class.authors, main = "")

#________________________________
# TRAINING & TESTING THE MODEL

model.class.authors <- LogisticRegression(train.df = class.allDF$TrainAut, test.df = class.allDF$TestAut,
                                        alpha = 0.5, lambda = cv.class.authors$lambda.1se,
                                        standardize = FALSE)

model.class.authors$betaPlot
```


### Order level
```{r order-authors-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#order.allDF <- Sampling(logratioDF = ratios.order, authorList = author_list) # to re-pool the samples
#table(test %in% rownames(order.allDF$TrainAut))

set.seed(123)
cv.order.authors <- cv.glmnet(x = order.allDF$TrainAut[,-1],
                              y = order.allDF$TrainAut[,1], # first column is disease
                              alpha = 1, standardize = FALSE,
                              family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.order.authors, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.order.authors <- LogisticRegression(train.df = order.allDF$TrainAut, test.df = order.allDF$TestAut,
                                          alpha = 1, lambda = cv.order.authors$lambda.1se,
                                          standardize = FALSE)

model.order.authors$betaPlot
```


### Family level
```{r family-authors-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#family.allDF <- Sampling(logratioDF = ratios.family, authorList = author_list) # to re-pool the samples
#table(test %in% rownames(family.allDF$TrainAut))

#set.seed(123)
cv.fam.authors <- cv.glmnet(x = family.allDF$TrainAut[,-1],
                            y = family.allDF$TrainAut[,1], # first column is disease
                            alpha = 0.7, standardize = FALSE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.fam.authors, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.fam.authors <- LogisticRegression(train.df = family.allDF$TrainAut, test.df = family.allDF$TestAut,
                                        alpha = 0.7, lambda = cv.fam.authors$lambda.1se,
                                        standardize = FALSE)

model.fam.authors$betaPlot
```


### Genus level
```{r genus-authors-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#genus.allDF <- Sampling(logratioDF = ratios.genus, authorList = author_list) # to re-pool samples into training & testing
#table(test %in% rownames(genus.allDF$TrainAut))

set.seed(123)
cv.genus.authors <- cv.glmnet(x = genus.allDF$TrainAut[,-1],
                              y = genus.allDF$TrainAut[,1], # first column is disease
                              alpha = 1, standardize = FALSE,
                              family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.genus.authors, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.genus.authors <- LogisticRegression(train.df = genus.allDF$TrainAut, test.df = genus.allDF$TestAut,
                                          alpha = 1, lambda = cv.genus.authors$lambda.1se,
                                          standardize = FALSE)

model.genus.authors$betaPlot
```




## 2 - RUN SPARSE LOGISTIC REGRESSION (WITH SEQUENCING TECHNOLOGY)

(1) Look at the misclassification error depending on the tuning parameter lambda with a 10-fold cross-validation, and using the sequencing technologies + log-ratios between taxa as potential predictors.
(2) Build the model with the lambda.1se (except for phylum level, prediction is too bad) & measure accuracy on training and testing dataframes.
(3) Repeat for all taxonomic levels.

### Phylum level
```{r phyla-seqTech-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#phyla.allDF <- Sampling(logratioDF = ratios.phyla, authorList = author_list) # to re-pool samples into training & testing
#table(test %in% rownames(phyla.allDF$TrainSeq))

set.seed(123)
cv.phy.seqTech <- cv.glmnet(x = phyla.allDF$TrainSeq[,-1],
                            y = phyla.allDF$TrainSeq[,1], # first column is disease
                            alpha = 1, standardize = TRUE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.phy.seqTech, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.phy.seqTech <- LogisticRegression(train.df = phyla.allDF$TrainSeq, test.df = phyla.allDF$TestSeq,
                                        alpha = 1, lambda = cv.phy.seqTech$lambda.min,
                                        standardize = TRUE)

model.phy.seqTech$betaPlot
```


### Class level
```{r class-seqTech-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#class.allDF <- Sampling(logratioDF = ratios.class, authorList = author_list) # to re-pool samples into training & testing
#test <- rownames(class.allDF$TrainSeq)
#table(test %in% rownames(class.allDF$TrainSeq))

set.seed(123)
cv.class.seqTech <- cv.glmnet(x = class.allDF$TrainSeq[,-1],
                            y = class.allDF$TrainSeq[,1], # first column is disease
                            alpha = 1, standardize = FALSE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.class.seqTech, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.class.seqTech <- LogisticRegression(train.df = class.allDF$TrainSeq, test.df = class.allDF$TestSeq,
                                        alpha = 1, lambda = cv.class.seqTech$lambda.1se,
                                        standardize = FALSE)

model.class.seqTech$betaPlot
```


### Order level
```{r order-seqTech-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#order.allDF <- Sampling(logratioDF = ratios.order, authorList = author_list) # to re-pool samples into training & testing
#test <- rownames(order.allDF$TrainSeq)
#table(test %in% rownames(order.allDF$TrainSeq))

set.seed(123)
cv.order.seqTech <- cv.glmnet(x = order.allDF$TrainSeq[,-1],
                            y = order.allDF$TrainSeq[,1], # first column is disease
                            alpha = 1, standardize = FALSE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.order.seqTech, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.order.seqTech <- LogisticRegression(train.df = order.allDF$TrainSeq, test.df = order.allDF$TestSeq,
                                        alpha = 1, lambda = cv.order.seqTech$lambda.1se,
                                        standardize = FALSE)

model.order.seqTech$betaPlot
```


### Family level

```{r family-seqTech-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#family.allDF <- Sampling(logratioDF = ratios.family, authorList = author_list)
#test <- rownames(family.allDF$TrainSeq)
#table(test %in% rownames(family.allDF$TrainSeq))

set.seed(123) # for reproducibility
cv.fam.seqTech <- cv.glmnet(x = family.allDF$TrainSeq[,-1],
                            y = family.allDF$TrainSeq[,1], # first column is disease
                            alpha = 1, standardize = FALSE,
                            family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.fam.seqTech, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.fam.seqTech <- LogisticRegression(train.df = family.allDF$TrainSeq, test.df = family.allDF$TestSeq,
                                        alpha = 1, lambda = cv.fam.seqTech$lambda.1se,
                                        standardize = FALSE)

model.fam.seqTech$betaPlot
```


### Genus level

```{r genus-seqTech-logistic-CV, fig.width = 7, fig.height = 5}
#________________________
# CROSS-VALIDATION

#genus.allDF <- Sampling(logratioDF = ratios.genus, authorList = author_list)
#test <- rownames(genus.allDF$TrainSeq)
#table(test %in% rownames(genus.allDF$TrainSeq))

set.seed(123)
cv.genus.seqTech <- cv.glmnet(x = genus.allDF$TrainSeq[,-1],
                              y = genus.allDF$TrainSeq[,1], # first column is disease
                              alpha = 1, standardize = FALSE,
                              family = "binomial", lambda = lambdas_to_try, type.measure = "class")
plot(cv.genus.seqTech, main = "")

#________________________________
# TRAINING & TESTING THE MODEL
model.genus.seqTech <- LogisticRegression(train.df = genus.allDF$TrainSeq, test.df = genus.allDF$TestSeq,
                                          alpha = 1, lambda = cv.genus.seqTech$lambda.1se,
                                          standardize = FALSE)

model.genus.seqTech$betaPlot
```



\n \n
_____________________________________________________________________________________
_____________________________________________________________________________________
\n \n


# RANDOM FOREST CLASSIFIER

## 1 - DEFINE FUNCTION

This function will run the random forest classifier model and return the accuracy of the model on the training & testing df. It also shows the importance of the predictive features, and plots the MeanDecreaseAccuracy (if removing one feature, how much it decreases the accuracy of the model).

```{r random-forest}
RandomForest <- function(train.df, test.df, nb.cv, ntree){
  
  #________________________
  # CROSS-VALIDATION
  
  # Fit the model on the training set
  set.seed(123)
  model.rF <- train(x = train.df[,-1],
                    y = as.factor(train.df[,1]), # first column is disease
                    ntree = ntree,
                    method = "rf", trControl = trainControl("cv", number = nb.cv), importance = TRUE)
  # Best tuning parameter
  #cat("-> Best tuning parameter:")
  #print(model.rF$bestTune)
  # Final model
  cat("\n-> Final model:")
  print(model.rF$finalModel)
  
  #________________________
  # RUN MODEL
  cat("\n+++++   Predicting disease phenotype on test dataframe  +++++ \n")
  
  # Make predictions on the test data
  trainPredicted <- model.rF %>% predict(train.df[,-1])
  testPredicted <- model.rF %>% predict(test.df[,-1])
  #head(testPredicted)
  
  # Compute model accuracy rate
  cat("The model is", mean(trainPredicted == train.df[, 1])*100,
      "% accurate on the TRAINING DATAFRAME, considering that the training dataframe contains",
      length(train.df[train.df[,1] == "1",1])*100/length(train.df[,1]), "% of IBS samples. \n")
  cat("The model is", mean(testPredicted == test.df[, 1])*100,
      "% accurate on the TESTING DATAFRAME, considering that the testing dataframe contains",
      length(test.df[test.df[,1] == "1",1])*100/length(test.df[,1]), "% of IBS samples. \n")
  
  # Look at variable importance
  #cat("\n Importance of features:\n")
  #print(importance(model.rF$finalModel))
  cat("\n Importance of features in percentage:\n")
  print(varImp(model.rF))
  
  # Plot MeanDecreaseAccuracy
  varImpPlot(model.rF$finalModel, type = 1)
  # Plot MeanDecreaseGini
  varImpPlot(model.rF$finalModel, type = 2)
  
  return(model.rF)
}
```



## 2 - RUN RANDOM FOREST CLASSIFIER (WITH AUTHORS)
(1) Call the _RandomForest_ function to run the model, compute its accuracy, and show the most important predictive features.
(2) Repeat for all taxonomic levels.

### Phylum level
```{r phyla-authors-randomForest, fig.width = 7, fig.height = 5}
#phyla.allDF <- Sampling(logratioDF = ratios.phyla, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(phyla.allDF$TrainAut)
#table(rownames(phyla.allDF$TrainAut) %in% test)

rForest.phy.authors <- RandomForest(train.df = phyla.allDF$TrainAut, test.df = phyla.allDF$TestAut, nb.cv = 10, ntree = 500)

```


### Class level
```{r class-authors-randomForest, fig.width = 7, fig.height = 5}
#class.allDF <- Sampling(logratioDF = ratios.class, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(class.allDF$TrainAut)
#table(rownames(class.allDF$TrainAut) %in% test)

rForest.class.authors <- RandomForest(train.df = class.allDF$TrainAut, test.df = class.allDF$TestAut, nb.cv = 10, ntree = 500)
```


### Order level
```{r order-authors-randomForest, fig.width = 7, fig.height = 5}
#order.allDF <- Sampling(logratioDF = ratios.order, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(order.allDF$TrainAut)
#table(rownames(order.allDF$TrainAut) %in% test)

rForest.order.authors <- RandomForest(train.df = order.allDF$TrainAut, test.df = order.allDF$TestAut, nb.cv = 10, ntree = 500)
```


### Family level
```{r family-authors-randomForest, fig.width = 7, fig.height = 5}
#family.allDF <- Sampling(logratioDF = ratios.family, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(family.allDF$TrainAut)
#table(rownames(family.allDF$TrainAut) %in% test)

rForest.fam.authors <- RandomForest(train.df = family.allDF$TrainAut, test.df = family.allDF$TestAut, nb.cv = 10, ntree = 500)
```


### Genus level
```{r genus-authors-randomForest, fig.width = 7, fig.height = 5}
#genus.allDF <- Sampling(logratioDF = ratios.genus, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(genus.allDF$TrainAut)
#table(rownames(genus.allDF$TrainAut) %in% test)

rForest.genus.authors <- RandomForest(train.df = genus.allDF$TrainAut, test.df = genus.allDF$TestAut, nb.cv = 10, ntree = 500)
```


## 3 - RUN RANDOM FOREST CLASSIFIER (WITH SEQTECH)
(1) Call the _RandomForest_ function to run the model, compute its accuracy, and show the most important predictive features.
(2) Repeat for all taxonomic levels.

### Phylum level
```{r phyla-seqTech-randomForest, fig.width = 7, fig.height = 5}
#phyla.allDF <- Sampling(logratioDF = ratios.phyla, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(phyla.allDF$TrainSeq)
#table(rownames(phyla.allDF$TrainSeq) %in% test)

rForest.phy.seqTech <- RandomForest(train.df = phyla.allDF$TrainSeq, test.df = phyla.allDF$TestSeq, nb.cv = 10, ntree = 500)
```


### Class level
```{r class-seqTech-randomForest, fig.width = 7, fig.height = 5}
#class.allDF <- Sampling(logratioDF = ratios.class, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(class.allDF$TrainSeq)
#table(rownames(class.allDF$TrainSeq) %in% test)

rForest.class.seqTech <- RandomForest(train.df = class.allDF$TrainSeq, test.df = class.allDF$TestSeq, nb.cv = 10, ntree = 500)

```


### Order level
```{r order-seqTech-randomForest, fig.width = 7, fig.height = 5}
#order.allDF <- Sampling(logratioDF = ratios.order, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(order.allDF$TrainSeq)
#table(rownames(order.allDF$TrainSeq) %in% test)

rForest.order.seqTech <- RandomForest(train.df = order.allDF$TrainSeq, test.df = order.allDF$TestSeq, nb.cv = 10, ntree = 500)
```


### Family level
```{r family-seqTech-randomForest, fig.width = 7, fig.height = 5}
#family.allDF <- Sampling(logratioDF = ratios.family, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(family.allDF$TrainSeq)
#table(rownames(family.allDF$TrainSeq) %in% test)

rForest.family.seqTech <- RandomForest(train.df = family.allDF$TrainSeq, test.df = family.allDF$TestSeq, nb.cv = 10, ntree = 500)

```


### Genus level
```{r genus-seqTech-randomForest, fig.width = 7, fig.height = 5}
#genus.allDF <- Sampling(logratioDF = ratios.genus, authorList = author_list) # re-pool the samples & split them into train/test
#test <- rownames(genus.allDF$TrainSeq)
#table(rownames(genus.allDF$TrainSeq) %in% test)

rForest.genus.seqTech <- RandomForest(train.df = genus.allDF$TrainSeq, test.df = genus.allDF$TestSeq, nb.cv = 10, ntree = 500)
```


