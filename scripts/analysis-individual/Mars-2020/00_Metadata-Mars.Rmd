---
title: "00_Metadata-Mars"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
---


```{r, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE,
                      root.dir = "~/Projects/MetaIBS/data/analysis-individual/Mars-2020/00_Metadata-Mars/")
```




***********
# 1. IMPORT
***********

## 1.1. Libraries
```{r import-libraries}
library("readxl")
library(data.table)
library(tidyverse)
```

## 1.2. Data
```{r import-data}
path <- "~/Projects/MetaIBS/data/analysis-individual/Mars-2020"

# Metadata table downloaded from the SRA
sra_metadata <- read.csv(file.path(path, "00_Metadata-Mars/MarsSraRunTable.txt"), header=TRUE, sep = ",")
head(sra_metadata)

# Import the supplementary ASV table from the paper
paper_supp <- read_excel(file.path(path, "00_Metadata-Mars/1-s2.0-S0092867420309983-mmc1.xlsx"),
                         sheet=3) # import sheet with info on biopsy metadata
head(paper_supp)
```




******************
# 2. CLEANUP TABLE
******************

Let's keep only the necessary information in the tables.

```{r cleanup-metadata}
# CLEANUP SRADF
sraDF <- sra_metadata %>%
  filter(Assay.Type == "AMPLICON") %>%
  select(all_of(c("Run", "title"))) %>%
  separate(col=title, into=c("host_ID", "time_point"), sep="v", remove=TRUE)
head(sraDF)
dim(sraDF) # 72 samples
length(unique(sraDF$host_ID)) # 39 individuals (3 less than indicated in the paper)

# CLEANUP PAPER SUPP
suppDF <- paper_supp %>%
  # Keep relevant columns
  rename(host_subtype = "Cohort",
         study_ID = "Study ID",
         time_point = "Time point",
         host_sex = "Gender",
         host_age = "Age",
         host_bmi = "BMI") %>%
  select(all_of(c("host_subtype", "study_ID", "time_point", "host_sex", "host_age", "host_bmi"))) %>%
  mutate(time_point = as.character(time_point)) %>%
  # Get host_ID
  separate(col=study_ID, into=c("void", "host_ID"), sep=4, remove=TRUE) %>%
  select(-void) %>%
  # Add host_disease
  mutate(host_disease=gsub("IBS.*", "IBS", host_subtype)) %>%
  mutate(host_subtype=replace(host_subtype, host_subtype=="Healthy", "HC")) %>%
  # Rename host_sex
  mutate(host_sex=replace(host_sex, host_sex=="F", "female"),
         host_sex=replace(host_sex, host_sex=="M", "male"))
head(suppDF)
dim(suppDF) # 71 samples
length(unique(suppDF$host_ID)) # 42 individuals (like indicated in the paper)
```




*****************
# 3. MERGE TABLES
*****************

Let's merge tables to get a metadata table we will use for downstream analyses.

```{r create-metadata-df}
# Let's check we can find all host_ID from SRA metadata in the supp. table and vice versa
setdiff(sraDF$host_ID, suppDF$host_ID)
setdiff(suppDF$host_ID, sraDF$host_ID) # there are 3 ID that are absent from the SRA table.

# MERGE TABLES
# As all ID in the SRA table can be found in the supp. table, we will merge the supp.table onto the SRA table.
clean.df <- left_join(sraDF, suppDF, by=c("host_ID", "time_point")) %>%
  # Fill in the few NAs (covariates missing for a few 2nd time points)
  group_by(host_ID) %>%
  fill(host_subtype, .direction="down") %>%
  fill(host_sex, .direction="down") %>%
  fill(host_age, .direction="down") %>%
  fill(host_bmi, .direction="down") %>%
  fill(host_disease, .direction="down") %>%
  ungroup() %>%
  # Add some covariates
  mutate(sample_type = "sigmoid") %>%
  rename(Collection = "time_point") %>%
  mutate(Collection=replace(Collection, Collection=="1", "1st"),
         Collection=replace(Collection, Collection=="2", "2nd")) %>%
  mutate(author = "Mars",
         sequencing_tech = "Illumina paired-end",
         variable_region = "V4")
head(clean.df)
dim(clean.df) # 72 samples
```




******************
# 4. SAVE METADATA
******************

## 4.1. Get list of links to wget fastq files from ENA
```{r save-data1}
# Open the filereport downloaded from the ENA
ena_table <- read.csv(file.path(path, "raw_fastq/filereport_read_run_PRJEB37924_tsv.txt"), header=T, sep="\t")
table(ena_table$run_accession %in% clean.df$Run, useNA="ifany") # 72 samples of interest and 532 that we don't want to download
ena_table <- ena_table[ena_table$run_accession %in% clean.df$Run,]
dim(ena_table) # 72 rows
head(ena_table)
# the fastq_ftp column contains both forward & reverse reads separated by ";"
ena_tableF <- ena_table[,c("run_accession", "fastq_ftp")]
ena_tableF$fastq_ftp <- gsub(";.*", "", ena_tableF$fastq_ftp)
ena_tableR <- ena_table[,c("run_accession", "fastq_ftp")]
ena_tableR$fastq_ftp <- gsub(".*;", "", ena_tableR$fastq_ftp)
ena_table_final <- rbind(ena_tableF, ena_tableR)
head(ena_table_final[order(ena_table_final$run_accession),])
table(ena_table_final$run_accession, useNA="ifany") # should all appear twice
```


## 4.2. Export metadata & fastq file links
```{r save-data2, echo=TRUE, eval=FALSE}
# Export metadata table
write.csv(clean.df, file.path(path, "00_Metadata-Mars/modif_metadata(R).csv"))

# Export the list of Runs to download from SRA
# write.table(clean.df$Run, file.path(path, "raw_fastq/list_files_mars.txt"),
#             sep="\t", row.names=FALSE, col.names=FALSE, quote=FALSE)

# Export the list of links to download the Runs from ENA
write.table(ena_table_final$fastq_ftp, file.path(path, "raw_fastq/list_files_mars.txt"),
            sep="\t", row.names=FALSE, col.names=FALSE, quote=FALSE)
```




*****************
# 5. SESSION INFO
*****************

```{r session-info}
sessionInfo()
```